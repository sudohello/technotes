---
Title: Autonomous Vechile
Decription: Autonomous Vechile
Author: Bhaskar Mangal
Date: 11th-Apr-2018
Tags: Autonomous Vechile
---

**Table of Contents**
* TOC
{:toc}


## Autonomous Vechile

## Lectures, Courses
* http://copypasteprogrammers.com/mit-6-s094-deep-learning-for-self-driving-cars-2018-lecture-5-notes-deep-learning-for-human-5cb0f53e4f15-2/
* https://www.coursera.org/lecture/convolutional-neural-networks/yolo-algorithm-fF3O0

## Different Levels of Autonomy
* https://jalopnik.com/whats-a-level-4-autonomous-car-this-chart-explains-eve-1785466324
* https://www.techrepublic.com/article/autonomous-driving-levels-0-to-5-understanding-the-differences/



## ApolloAuto
- https://github.com/ApolloAuto/apollo
- http://www.acrosser.com/

**dev center**
- http://apollo.auto/devcenter/devcenter.html

**apollo videos**
- https://www.youtube.com/watch?v=WelxS19p9mE
- https://www.youtube.com/watch?v=EEOHr3zZoY4
- https://www.youtube.com/watch?v=Y70Me-Cr8ls
- https://www.youtube.com/watch?v=pLW6uaLZmpA
- https://www.youtube.com/watch?v=DGRmoJ9gFdk

**News, Blogs, Articles**
- https://opensource.com/article/18/4/apollo-open-autonomous-vehicle-platform
- https://pandaily.com/ai-feast-at-baidu-create-2018-level-4-autonomous-bus-apollo-3-0-dueros-3-0/
- https://www.blackducksoftware.com/open-source-rookies-2018
  * Moving into 2018, the Apollo team is focusing on productization requirements to extend innovation to a greater portfolio of businesses, while upholding one of its core tenets: Autonomous driving data belongs to humankind, not solely to the company, and the more we all contribute, the more we will benefit from this project. 
- https://medium.com/@Synced/baidu-apollo-releases-massive-self-driving-dataset-teams-up-with-berkeley-deepdrive-5e785ab4053b
- https://medium.com/syncedreview/baidu-all-in-ai-dueros-and-apollo-open-platforms-dc5cdf88e8ed
- Both DuerOS and Apollo operate based on the Baidu Brain and Baidu Cloud services
* [ApolloScape - Apollo Dataset](apolloscape-dataset.md)
* Next-Gen Simulation
  - Use of simulation environments for autonomous driving is getting a lot of attention in the automobile and computing industry. The key challenges include safety considerations that arise when an autonomous vehicle navigates the roads surrounded by other vehicles, bicycles, or pedestrians. In order to perform extensive testing and evaluations, we need to develop good simulation systems that can be used to test these vehicle not only in typical, relatively safe scenarios, but also in uncertain and dangerous environments. Our current open simulation tools include WorldSim and LogSim. We are also developing next generation technologies that can be used to generate realistic simulations of real-world traffic scenarios and driver behaviors.

**Installation**
- https://github.com/ApolloAuto/apollo/blob/master/docs/howto/how_to_run_apollo_3.0_with_ubuntu16.md


## Apollo Modules

### Perception
* https://github.com/ApolloAuto/apollo/tree/master/modules/perception



## CAN, Accutators, Sensors etc
https://www.peak-system.com/PCAN-Cable-3.290.0.html?&L=1
https://www.peak-system.com/PCAN-USB.199.0.html?&L=1
some CAN related info but the interfaces which is used to read CAN data from car looks different.
https://core.ac.uk/download/pdf/41984076.pdf

ROS based CAN subscriber
http://wiki.ros.org/cob_generic_can

## Europilot
- https://github.com/marsauto/europilot

## Autoware
- https://github.com/CPFL/Autoware
Open-source software for urban autonomous driving, maintained by Tier IV. The following functions are supported:

* 3D Localization
* 3D Mapping
* Path Planning
* Path Following
* Accel/Brake/Steering Control
* Data Logging
* Car/Pedestrian/Object Detection
* Traffic Signal Detection
* Traffic Light Recognition
* Lane Detection
* Object Tracking
* Sensor Calibration
* Sensor Fusion
* Cloud-oriented Maps
* Connected Automation
* Smartphone Navigation
* Software Simulation
* Virtual Reality

## Nvidia Driveworks
- https://www.nvidia.com/en-us/self-driving-cars/drive-platform/

## http://comma.ai/

## Navigation Standards
- https://www.nds-association.org/

## Open Autonomous Safety
- https://voyage.auto/open-autonomous-safety/

## Others
- https://www.producthunt.com/alternatives/scale-self-driving-training-api
- https://www.theverge.com/2016/11/30/13779336/comma-ai-autopilot-canceled-autonomous-car-software-free

## Misc
- http://aid-driving.eu/active-learning-and-labeling/

## Software and Hardware Components
* http://openxcplatform.com/
* https://shop.openxcplatform.com/
* https://github.com/openxc/openxc-message-format/blob/master/JSON.mkd
* https://mechanics.stackexchange.com/questions/17634/read-steering-angle-data-in-real-time

## OpenDrive, OpenCRG, OpenScenario
* http://www.opendrive.org/
* http://opencrg.org/
* https://en.wikipedia.org/wiki/OpenCRG
* http://openscenario.org/
* https://www.road-xml.org/

**Apollo OpenDrive Specification**
* https://github.com/ApolloAuto/apollo/issues/3005
* https://github.com/ApolloAuto/apollo/issues/603


ASAM - Standardization for Automotive Development
* https://www.asam.net/
* https://www.asam.net/about-asam/technology/

**Digitizing OpenDrive Road Data**
* http://www.atlatec.de/en/open-drive-sample-data/
* http://www.atlatec.de/en/products/atlamap/
* https://www.mathworks.com/help/driving/ug/add-opendrive-roads-to-driving-scenario.html
* https://stackoverflow.com/questions/48884655/python-opendrive-map-spiral-clothoid-euler-spiral-curu-spiral-interpol

* vector zero
  - https://www.youtube.com/watch?v=5Si77LULrNo
* Trian3d-Builder
https://triangraphics.de/?q=en/produkte/Trian3d-Builder
* vterrain
  - http://vterrain.org/Culture/Roads/
* VTD - Virtual Test Drive by Vires
  - https://vires.com/vtd-vires-virtual-test-drive/
  - https://www.youtube.com/watch?v=SGQ0VxhMcmw
* RightHook 
  - https://righthook.io/
* cognata
  - http://www.cognata.com/

**Simulators Only**
* Carla
  - http://carla.org/
  - https://github.com/carla-simulator/carla
* Udacity
  - https://github.com/udacity/self-driving-car-sim
  - https://towardsdatascience.com/introduction-to-udacity-self-driving-car-simulator-4d78198d301d

**Deep Learning in Autonomy**
* https://www.slideshare.net/yuhuang/3d-interpretation-from-single-2d-image-for-autonomous-driving-121650450
* Camera based Lane Detection
  - https://www.slideshare.net/yuhuang/camerabased-lane-detection-by-deep-learning
  - DVCNN - Dual View CNN for accurate lane detection
  - VPGNet - Vanishing Point Guided Network for lane and road marking detection and recogition
  - SCNN - Spatial CNN
    * probability maps of baseline - ReNet, MRFNet, ResNet-101, SCNN
* 3D Scene Construction
  - https://sites.google.com/site/yorkyuhuang/home/tutorial/deep-learning-1/deeplearningforscenereconstruction
* Topics
  - NMS: Non maximal supression
    - https://arxiv.org/pdf/1705.02950.pdf
  - convert the segmentation mask to polygon
    - https://github.com/cocodataset/cocoapi/issues/39
    - https://docs.opencv.org/trunk/d4/d73/tutorial_py_contours_begin.html
    - https://gist.github.com/hellpanderrr/2c08af0f07eed4782234
    - http://blog.thehumangeo.com/2014/05/12/drawing-boundaries-in-python/

* Mask_RCNN
  - https://stackoverflow.com/questions/49684468/mask-r-cnn-for-object-detection-and-segmentation-train-for-a-custom-dataset

You need to have all your annotations.
All of those need to be converted to VGG Polygon schema (yes i mean polygons). I have added a sample VGG Polygon format at the end of this answer.
You need to divide your custom dataset into train, test and val
The annotation by default are looked with a filename via_region_data.json inside the individual dataset folder. For eg for training images it would look at train\via_region_data.json. You can also change it if you want.
Inside Samples folder you can find folders like Balloon, Nucleus, Shapes etc. Copy one of the folders. Preferably balloon. We will now try to modify this new folder for our custom dataset.
Inside the copied folder, you will have a .py file (for balloon it will be balloon.py), change the following variables
ROOT_DIR : the absolute path where you have cloned the project
DEFAULT_LOGS_DIR : This folder will get bigger in size so change this path accordingly (if you are running your code in a low disk storage VM). It will store the .h5 file as well. It will make subfolder inside the log folder with timestamp attached to it.
.h5 files are roughly 200 - 300 MB per epoch. But guess what this log directory is Tensorboard compatible. You can pass the timestamped subfolder as --logdir argument while running tensorboard.
This .py file also has two classes - one class with suffix as Config and another class with suffix as Dataset.


**Python in GIS**
* http://toblerity.org/shapely/
  * pip install shapely
* http://toblerity.org/fiona/
  * loading gis data
**Resources**
* https://sites.google.com/site/yorkyuhuang/home/tutorial - very interesting k-bank slides
* http://www.akshaysoam.com/#/projects
https://oclavi.com/

http://www.transportationtechnologyventures.com/simwiki/index.php?title=Modeling - Best Resource of 3d road construction
https://www.slideshare.net/yuhuang/visualization-and-simulation-for-adas-and-autonomous-driving



**Datasets**
* FCAV
Driving in the Matrix: Can Virtual Worlds Replace Human-Generated Annotations for Real World Tasks?
  - https://arxiv.org/abs/1610.01983
  - https://fcav.engin.umich.edu/safety-pilot-dataset
  - https://fcav.engin.umich.edu/sim-dataset
  - https://github.com/umautobots/driving-in-the-matrix
  - https://github.com/umautobots/GTAVisionExport
